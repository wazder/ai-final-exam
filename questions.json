[{"id": 1, "code": "SN1-1", "category": "PDF 1", "fp_tag": "FP", "question": "Why do definitions of Artificial Intelligence differ among researchers?", "options": ["AI is already fully understood", "Intelligence has multiple dimensions and interpretations", "There is a single formal definition", "AI systems are identical"], "correct": 1}, {"id": 2, "code": "SN1-2", "category": "PDF 1", "fp_tag": "FP", "question": "Who introduced the term “Artificial Intelligence”?", "options": ["Alan Turing", "John McCarthy", "Marvin Minsky", "Claude Shannon"], "correct": 1}, {"id": 3, "code": "SN1-3", "category": "PDF 1", "fp_tag": "FP", "question": "What is the primary goal of Artificial Intelligence according to John McCarthy?", "options": ["To simulate the human brain exactly", "To replace human intelligence", "To build machines that behave intelligently", "To eliminate uncertainty"], "correct": 2}, {"id": 4, "code": "SN1-4", "category": "PDF 1", "fp_tag": "FP", "question": "What does the Turing Test evaluate?", "options": ["Computational speed", "Hardware efficiency", "Human-like intelligent behavior", "Learning accuracy"], "correct": 2}, {"id": 5, "code": "SN1-5", "category": "PDF 1", "fp_tag": "", "question": "Which component is fundamental to the concept of intelligent agents?", "options": ["Randomness", "Emotion", "Perception and action", "Fixed rules only"], "correct": 2}, {"id": 6, "code": "SN2-1", "category": "PDF 2", "fp_tag": "FP", "question": "What is the main limitation of propositional logic compared to predicate logic?", "options": ["It cannot represent truth values", "It lacks variables and quantifiers", "It cannot use logical operators", "It is undecidable"], "correct": 1}, {"id": 7, "code": "SN2-2", "category": "PDF 2", "fp_tag": "FP", "question": "Which symbol represents universal quantification?", "options": ["∃", "→", "∀", "∧"], "correct": 2}, {"id": 8, "code": "SN2-3", "category": "PDF 2", "fp_tag": "FP", "question": "What does the existential quantifier (∃) express?", "options": ["All elements satisfy a property", "No elements satisfy a property", "At least one element satisfies a property", "Exactly one element satisfies a property"], "correct": 2}, {"id": 9, "code": "SN2-4", "category": "PDF 2", "fp_tag": "FP", "question": "What is the role of semantics in logic?", "options": ["Define valid syntax", "Assign meaning to formulas", "Generate inference rules", "Optimize proofs"], "correct": 1}, {"id": 10, "code": "SN2-5", "category": "PDF 2", "fp_tag": "FP", "question": "What does it mean for a formula to be **satisfiable**?", "options": ["It is syntactically correct", "It is provable", "It is true under some interpretation", "It is always false"], "correct": 2}, {"id": 11, "code": "SN2-6", "category": "PDF 2", "fp_tag": "FP", "question": "Which logical method is commonly used for automated theorem proving?", "options": ["Gradient descent", "Resolution", "Hebbian learning", "Backpropagation"], "correct": 1}, {"id": 12, "code": "SN2-7", "category": "PDF 2", "fp_tag": "", "question": "Why does the use of quantifiers increase reasoning complexity?", "options": ["They remove variables", "They create infinite domains", "They eliminate inference rules", "They simplify models"], "correct": 1}, {"id": 13, "code": "SN2-8", "category": "PDF 2", "fp_tag": "", "question": "Which logic is fully decidable?", "options": ["First-order predicate logic", "Higher-order logic", "Propositional logic", "Default logic"], "correct": 2}, {"id": 14, "code": "SN2-9", "category": "PDF 2", "fp_tag": "", "question": "What does a **model** represent in logic?", "options": ["A proof procedure", "A truth assignment making formulas true", "A set of inference rules", "A database query"], "correct": 1}, {"id": 15, "code": "SN2-10", "category": "PDF 2", "fp_tag": "", "question": "Why is predicate logic more suitable for real-world knowledge representation?", "options": ["It avoids uncertainty", "It supports relations and quantification", "It is computationally simpler", "It eliminates ambiguity"], "correct": 1}, {"id": 16, "code": "SN3-1", "category": "PDF 3", "fp_tag": "FP", "question": "What does it mean for first-order logic to be **semi-decidable**?", "options": ["Every formula can be proven true or false", "All inference procedures terminate", "True statements can be proven, but termination is not guaranteed", "False statements are always detected"], "correct": 2}, {"id": 17, "code": "SN3-2", "category": "PDF 3", "fp_tag": "FP", "question": "What is the **search space problem** in logic-based AI systems?", "options": ["Lack of inference rules", "Exponential growth of possible inference paths", "Incomplete knowledge bases", "Limited memory of machines"], "correct": 1}, {"id": 18, "code": "SN3-3", "category": "PDF 3", "fp_tag": "FP", "question": "Why does automated reasoning become impractical in large search spaces?", "options": ["Rules become incorrect", "Proofs require infinite memory", "The number of inference steps grows explosively", "Logic loses consistency"], "correct": 2}, {"id": 19, "code": "SN3-4", "category": "PDF 3", "fp_tag": "FP", "question": "What does Gödel’s incompleteness theorem imply for logical systems?", "options": ["All true statements are provable", "All systems are inconsistent", "Some true statements cannot be proven within the system", "Logic is obsolete"], "correct": 2}, {"id": 20, "code": "SN3-5", "category": "PDF 3", "fp_tag": "FP", "question": "What key limitation of classical logic is illustrated by the Flying Penguin problem?", "options": ["Lack of expressiveness", "Inability to handle exceptions", "Lack of quantifiers", "Computational inefficiency"], "correct": 1}, {"id": 21, "code": "SN3-6", "category": "PDF 3", "fp_tag": "FP", "question": "What type of reasoning allows exceptions to default rules?", "options": ["Deductive reasoning", "Probabilistic reasoning", "Non-monotonic reasoning", "Symbolic reasoning"], "correct": 2}, {"id": 22, "code": "SN3-7", "category": "PDF 3", "fp_tag": "FP", "question": "In Prolog, what mechanism allows the system to explore alternative solutions?", "options": ["Forward chaining", "Resolution only", "Backtracking", "Gradient descent"], "correct": 2}, {"id": 23, "code": "SN3-8", "category": "PDF 3", "fp_tag": "FP", "question": "What is the role of **unification** in Prolog?", "options": ["Assign truth values", "Match terms and variables", "Optimize search trees", "Control recursion depth"], "correct": 1}, {"id": 24, "code": "SN3-9", "category": "PDF 3", "fp_tag": "", "question": "Why can Prolog programs fail to terminate?", "options": ["Lack of inference rules", "Infinite recursion in the search space", "Incorrect syntax", "Missing facts"], "correct": 1}, {"id": 25, "code": "SN3-10", "category": "PDF 3", "fp_tag": "", "question": "Which statement best summarizes the limitations of pure logic in AI?", "options": ["Logic is too expressive", "Logic cannot represent facts", "Logic struggles with uncertainty and scalability", "Logic replaces learning"], "correct": 2}, {"id": 26, "code": "SN4-1", "category": "PDF 4", "fp_tag": "FP", "question": "What is the main cause of the search space explosion problem in AI?", "options": ["Low branching factor", "High branching factor and large depth", "Deterministic environments", "Limited state representations"], "correct": 1}, {"id": 27, "code": "SN4-2", "category": "PDF 4", "fp_tag": "FP", "question": "What does the term **search space** refer to?", "options": ["The set of all input values", "The collection of all possible states to be explored", "Only the goal states", "The heuristic function"], "correct": 1}, {"id": 28, "code": "SN4-3", "category": "PDF 4", "fp_tag": "FP", "question": "Why is exhaustive search usually infeasible for large problems?", "options": ["It requires symbolic reasoning", "The number of possible states grows exponentially", "It lacks optimality", "It cannot find solutions"], "correct": 1}, {"id": 29, "code": "SN4-4", "category": "PDF 4", "fp_tag": "FP", "question": "Which search strategy explores all nodes at a given depth before going deeper?", "options": ["Depth-First Search (DFS)", "Breadth-First Search (BFS)", "Heuristic Search", "A* Search"], "correct": 1}, {"id": 30, "code": "SN4-5", "category": "PDF 4", "fp_tag": "FP", "question": "Which property is guaranteed by Breadth-First Search if all step costs are equal?", "options": ["Minimum memory usage", "Optimality", "Heuristic efficiency", "Incompleteness"], "correct": 1}, {"id": 31, "code": "SN4-6", "category": "PDF 4", "fp_tag": "FP", "question": "What is a major drawback of Breadth-First Search?", "options": ["It is incomplete", "It may get stuck in loops", "It requires large memory", "It is not systematic"], "correct": 2}, {"id": 32, "code": "SN4-7", "category": "PDF 4", "fp_tag": "FP", "question": "Which search strategy explores as deep as possible before backtracking?", "options": ["BFS", "DFS", "A*", "Greedy search"], "correct": 1}, {"id": 33, "code": "SN4-8", "category": "PDF 4", "fp_tag": "FP", "question": "What is a key advantage of Depth-First Search?", "options": ["Optimality", "Completeness", "Low memory usage", "Use of heuristics"], "correct": 2}, {"id": 34, "code": "SN4-9", "category": "PDF 4", "fp_tag": "FP", "question": "Why can Depth-First Search fail to find a solution?", "options": ["It uses too much memory", "It may follow infinite paths", "It requires heuristics", "It is probabilistic"], "correct": 1}, {"id": 35, "code": "SN4-10", "category": "PDF 4", "fp_tag": "FP", "question": "What is the main purpose of heuristic search?", "options": ["To guarantee optimality without cost", "To reduce the effective search space", "To eliminate uncertainty", "To replace state representation"], "correct": 1}, {"id": 36, "code": "SN4-11", "category": "PDF 4", "fp_tag": "FP", "question": "Which algorithm combines path cost and heuristic estimation?", "options": ["BFS", "DFS", "A* search", "Minimax"], "correct": 2}, {"id": 37, "code": "SN4-12", "category": "PDF 4", "fp_tag": "FP", "question": "When is A* search guaranteed to find an optimal solution?", "options": ["When the heuristic is random", "When the heuristic is admissible", "When the branching factor is small", "When costs are ignored"], "correct": 1}, {"id": 38, "code": "SN4-13", "category": "PDF 4", "fp_tag": "FP", "question": "Which type of problem does the **minimax algorithm** address?", "options": ["Single-agent optimization", "Probabilistic reasoning", "Two-player adversarial games", "Unsupervised clustering"], "correct": 2}, {"id": 39, "code": "SN4-14", "category": "PDF 4", "fp_tag": "FP", "question": "What is the purpose of alpha–beta pruning?", "options": ["Increase search depth", "Improve heuristic accuracy", "Reduce the number of evaluated nodes", "Guarantee faster convergence"], "correct": 2}, {"id": 40, "code": "SN4-15", "category": "PDF 4", "fp_tag": "", "question": "Which statement best explains why humans outperform brute-force search in complex problems?", "options": ["Humans evaluate all possibilities", "Humans use heuristics and intuition", "Humans avoid search entirely", "Humans rely on randomness"], "correct": 1}, {"id": 41, "code": "SN5-1", "category": "PDF 5", "fp_tag": "FP", "question": "Why is classical logic insufficient for reasoning in real-world situations?", "options": ["It is computationally inefficient", "It assumes binary true/false values", "It cannot represent symbols", "It requires complete datasets"], "correct": 1}, {"id": 42, "code": "SN5-2", "category": "PDF 5", "fp_tag": "FP", "question": "What main issue is illustrated by the Flying Penguin (Tweety) problem?", "options": ["Lack of inference rules", "Inability to represent learning", "Failure of monotonic reasoning with exceptions", "Incorrect probability estimates"], "correct": 2}, {"id": 43, "code": "SN5-3", "category": "PDF 5", "fp_tag": "FP", "question": "What does monotonic reasoning mean in classical logic?", "options": ["Conclusions become more accurate with new facts", "Conclusions never change when new facts are added", "Conclusions are probabilistic", "Conclusions depend on thresholds"], "correct": 1}, {"id": 44, "code": "SN5-4", "category": "PDF 5", "fp_tag": "FP", "question": "Why does learning that “Tweety is a penguin” cause a problem in classical logic?", "options": ["Penguins are mammals", "It contradicts a default rule", "It removes all previous knowledge", "It creates cyclic reasoning"], "correct": 1}, {"id": 45, "code": "SN5-5", "category": "PDF 5", "fp_tag": "FP", "question": "Which type of reasoning allows conclusions to be withdrawn when new information appears?", "options": ["Deductive reasoning", "Inductive reasoning", "Non-monotonic reasoning", "Symbolic reasoning"], "correct": 2}, {"id": 46, "code": "SN5-6", "category": "PDF 5", "fp_tag": "FP", "question": "What is the core idea behind using probabilities in AI reasoning?", "options": ["To eliminate uncertainty", "To assign degrees of belief instead of absolute truth", "To speed up inference", "To replace logic completely"], "correct": 1}, {"id": 47, "code": "SN5-7", "category": "PDF 5", "fp_tag": "FP", "question": "What does conditional probability P(A | B) represent?", "options": ["Probability of B given A", "Joint probability of A and B", "Probability of A given B", "Marginal probability of A"], "correct": 2}, {"id": 48, "code": "SN5-8", "category": "PDF 5", "fp_tag": "FP", "question": "Which theorem formally relates conditional and prior probabilities?", "options": ["De Morgan’s Law", "Bayes’ Theorem", "Law of Large Numbers", "Resolution Theorem"], "correct": 1}, {"id": 49, "code": "SN5-9", "category": "PDF 5", "fp_tag": "FP", "question": "In Bayesian reasoning, what does the **prior probability** represent?", "options": ["Updated belief after evidence", "Probability of evidence", "Initial belief before observing evidence", "Error probability"], "correct": 2}, {"id": 50, "code": "SN5-10", "category": "PDF 5", "fp_tag": "FP", "question": "What does the **posterior probability** represent?", "options": ["Initial belief", "Probability before evidence", "Updated belief after evidence", "Joint probability"], "correct": 2}, {"id": 51, "code": "SN5-11", "category": "PDF 5", "fp_tag": "FP", "question": "Why is Bayesian updating important in AI systems?", "options": ["It removes noise", "It allows beliefs to change with new evidence", "It guarantees correctness", "It simplifies logic rules"], "correct": 1}, {"id": 52, "code": "SN5-12", "category": "PDF 5", "fp_tag": "FP", "question": "Which early expert system used certainty factors instead of full probability theory?", "options": ["LEXMED", "MYCIN", "PROLOG", "SHRDLU"], "correct": 1}, {"id": 53, "code": "SN5-13", "category": "PDF 5", "fp_tag": "FP", "question": "Why were certainty factors used in early expert systems?", "options": ["Probability theory was unknown", "They were easier to implement than full probabilistic models", "They guaranteed optimal decisions", "They eliminated uncertainty"], "correct": 1}, {"id": 54, "code": "SN5-14", "category": "PDF 5", "fp_tag": "FP", "question": "What is a key limitation of certainty factors compared to Bayesian probability?", "options": ["They are computationally expensive", "They lack a solid mathematical foundation", "They require too much data", "They cannot handle rules"], "correct": 1}, {"id": 55, "code": "SN5-15", "category": "PDF 5", "fp_tag": "FP", "question": "What structure defines a Bayesian network?", "options": ["Undirected cyclic graph", "Directed acyclic graph with probabilities", "Decision tree with rules", "Fully connected neural network"], "correct": 1}, {"id": 56, "code": "SN5-16", "category": "PDF 5", "fp_tag": "FP", "question": "In a Bayesian network, what do nodes represent?", "options": ["Logical rules", "Random variables", "Class labels only", "Feature vectors"], "correct": 1}, {"id": 57, "code": "SN5-17", "category": "PDF 5", "fp_tag": "FP", "question": "What do edges in a Bayesian network indicate?", "options": ["Temporal order", "Causal certainty", "Direct probabilistic dependencies", "Logical implication only"], "correct": 2}, {"id": 58, "code": "SN5-18", "category": "PDF 5", "fp_tag": "FP", "question": "What is the role of Conditional Probability Tables (CPTs)?", "options": ["Store training data", "Define P(Node | Parents)", "Perform inference automatically", "Encode logical rules"], "correct": 1}, {"id": 59, "code": "SN5-19", "category": "PDF 5", "fp_tag": "", "question": "Which property allows Bayesian networks to simplify complex probability calculations?", "options": ["Complete connectivity", "Conditional independence", "Logical consistency", "Linear separability"], "correct": 1}, {"id": 60, "code": "SN5-20", "category": "PDF 5", "fp_tag": "", "question": "Which real-world application commonly uses Bayesian networks?", "options": ["Sorting algorithms", "Medical diagnosis", "Compiler optimization", "Text rendering"], "correct": 1}, {"id": 61, "code": "SN6-1", "category": "PDF 6", "fp_tag": "FP", "question": "What is the main difference between traditional programming and machine learning?", "options": ["Machine learning uses no algorithms", "Traditional programming learns from data", "Machine learning derives behavior from data instead of explicit rules", "Traditional programming is probabilistic"], "correct": 2}, {"id": 62, "code": "SN6-2", "category": "PDF 6", "fp_tag": "FP", "question": "In machine learning, what does the term **generalization** refer to?", "options": ["Perfect performance on training data", "Ability to perform well on unseen data", "Increasing model complexity", "Memorizing examples"], "correct": 1}, {"id": 63, "code": "SN6-3", "category": "PDF 6", "fp_tag": "FP", "question": "What problem occurs when a model fits training data too closely?", "options": ["Generalization", "Underfitting", "Overfitting", "Feature selection"], "correct": 2}, {"id": 64, "code": "SN6-4", "category": "PDF 6", "fp_tag": "FP", "question": "Why is overfitting undesirable in machine learning?", "options": ["It increases training speed", "It reduces performance on new data", "It simplifies the model", "It guarantees accuracy"], "correct": 1}, {"id": 65, "code": "SN6-5", "category": "PDF 6", "fp_tag": "FP", "question": "Which type of learning uses labeled training data?", "options": ["Unsupervised learning", "Reinforcement learning", "Supervised learning", "Evolutionary learning"], "correct": 2}, {"id": 66, "code": "SN6-6", "category": "PDF 6", "fp_tag": "FP", "question": "Which type of learning discovers patterns without labeled outputs?", "options": ["Supervised learning", "Unsupervised learning", "Reinforcement learning", "Transfer learning"], "correct": 1}, {"id": 67, "code": "SN6-7", "category": "PDF 6", "fp_tag": "FP", "question": "In Ertel’s apple classification example, what is the learning goal?", "options": ["Predict apple prices", "Separate apples into predefined classes", "Detect outliers only", "Sort apples by size"], "correct": 1}, {"id": 68, "code": "SN6-8", "category": "PDF 6", "fp_tag": "FP", "question": "What does a **learning agent** formally represent?", "options": ["A hard-coded decision system", "A function mapping features to outputs", "A symbolic reasoning engine", "A database query"], "correct": 1}, {"id": 69, "code": "SN6-9", "category": "PDF 6", "fp_tag": "FP", "question": "Why must a learning agent be evaluated on test data?", "options": ["To increase training size", "To verify generalization ability", "To reduce features", "To remove noise"], "correct": 1}, {"id": 70, "code": "SN6-10", "category": "PDF 6", "fp_tag": "FP", "question": "Which component is essential for training a supervised learning agent?", "options": ["Unlabeled data", "Reward signals only", "Labeled examples", "Random weights"], "correct": 2}, {"id": 71, "code": "SN6-11", "category": "PDF 6", "fp_tag": "FP", "question": "What is the main purpose of **feature selection**?", "options": ["Increase dataset size", "Improve accuracy and efficiency", "Remove labels", "Increase model depth"], "correct": 1}, {"id": 72, "code": "SN6-12", "category": "PDF 6", "fp_tag": "FP", "question": "Which phrase summarizes a common issue in data analysis?", "options": ["“More data, less noise”", "“Garbage in, garbage out”", "“Accuracy beats simplicity”", "“Features are optional”"], "correct": 1}, {"id": 73, "code": "SN6-13", "category": "PDF 6", "fp_tag": "FP", "question": "What is the first step in the data mining process?", "options": ["Pattern evaluation", "Feature selection", "Data collection", "Model deployment"], "correct": 2}, {"id": 74, "code": "SN6-14", "category": "PDF 6", "fp_tag": "FP", "question": "Which step transforms raw data into a suitable format for learning?", "options": ["Evaluation", "Data preprocessing", "Classification", "Visualization"], "correct": 1}, {"id": 75, "code": "SN6-15", "category": "PDF 6", "fp_tag": "FP", "question": "What is the output of the data mining process?", "options": ["Raw data", "Hardware configuration", "Patterns or knowledge", "Feature vectors only"], "correct": 2}, {"id": 76, "code": "SN6-16", "category": "PDF 6", "fp_tag": "FP", "question": "Why is preprocessing important before learning?", "options": ["It increases randomness", "It removes the need for training", "It improves data quality", "It eliminates uncertainty"], "correct": 2}, {"id": 77, "code": "SN6-17", "category": "PDF 6", "fp_tag": "", "question": "Which step evaluates the usefulness of discovered patterns?", "options": ["Data collection", "Feature extraction", "Evaluation", "Transformation"], "correct": 2}, {"id": 78, "code": "SN6-18", "category": "PDF 6", "fp_tag": "FP", "question": "What does the term **training phase** refer to?", "options": ["Deploying the model", "Learning from labeled or unlabeled data", "Testing generalization only", "Feature removal"], "correct": 1}, {"id": 79, "code": "SN6-19", "category": "PDF 6", "fp_tag": "", "question": "Which factor most strongly influences a model’s ability to generalize?", "options": ["Dataset size and diversity", "Hardware speed", "Programming language", "Output format"], "correct": 0}, {"id": 80, "code": "SN6-20", "category": "PDF 6", "fp_tag": "FP", "question": "Why is testing on unseen data critical?", "options": ["To increase overfitting", "To validate learning performance", "To reduce training cost", "To optimize hardware"], "correct": 1}, {"id": 81, "code": "SN6-21", "category": "PDF 6", "fp_tag": "", "question": "Which learning paradigm uses reward signals rather than labels?", "options": ["Supervised learning", "Unsupervised learning", "Reinforcement learning", "Statistical learning"], "correct": 2}, {"id": 82, "code": "SN6-22", "category": "PDF 6", "fp_tag": "FP", "question": "Which task best represents a classification problem?", "options": ["Predicting temperature", "Grouping similar documents", "Assigning spam or non-spam labels", "Reducing dimensionality"], "correct": 2}, {"id": 83, "code": "SN6-23", "category": "PDF 6", "fp_tag": "", "question": "Which task best represents a clustering problem?", "options": ["Assigning known labels", "Predicting continuous outputs", "Discovering groups without labels", "Maximizing margins"], "correct": 2}, {"id": 84, "code": "SN6-24", "category": "PDF 6", "fp_tag": "FP", "question": "Why is machine learning preferred over traditional programming in complex tasks?", "options": ["It requires no data", "Explicit rules are difficult to define", "It avoids computation", "It guarantees correctness"], "correct": 1}, {"id": 85, "code": "SN6-25", "category": "PDF 6", "fp_tag": "", "question": "Which statement best summarizes machine learning?", "options": ["Rule-based automation", "Manual decision-making", "Learning patterns from data", "Symbolic inference only"], "correct": 2}, {"id": 86, "code": "SN7-1", "category": "PDF 7", "fp_tag": "FP", "question": "What is the fundamental assumption of the Naive Bayes classifier?", "options": ["Features are linearly separable", "Features are conditionally independent given the class", "Classes have equal prior probabilities", "Training data is noise-free"], "correct": 1}, {"id": 87, "code": "SN7-2", "category": "PDF 7", "fp_tag": "FP", "question": "Why can Naive Bayes still perform well even when the independence assumption is violated?", "options": ["It uses deep architectures", "Errors often cancel out in probability estimation", "It ignores irrelevant features automatically", "It relies on rule-based inference"], "correct": 1}, {"id": 88, "code": "SN7-3", "category": "PDF 7", "fp_tag": "FP", "question": "Which probability does Naive Bayes compute to perform classification?", "options": ["P(Features)", "P(Class | Features)", "P(Features | Features)", "P(Class | Class)"], "correct": 1}, {"id": 89, "code": "SN7-4", "category": "PDF 7", "fp_tag": "FP", "question": "Which theorem provides the mathematical foundation for Naive Bayes?", "options": ["Central Limit Theorem", "Bayes’ Theorem", "Law of Large Numbers", "Chain Rule of Calculus"], "correct": 1}, {"id": 90, "code": "SN7-5", "category": "PDF 7", "fp_tag": "FP", "question": "What is a key limitation of the perceptron model?", "options": ["It requires too much memory", "It can only learn linearly separable patterns", "It cannot handle numerical data", "It is unsupervised"], "correct": 1}, {"id": 91, "code": "SN7-6", "category": "PDF 7", "fp_tag": "FP", "question": "How do multi-layer neural networks overcome the perceptron’s limitation?", "options": ["By using symbolic rules", "By introducing hidden layers", "By reducing input features", "By removing activation functions"], "correct": 1}, {"id": 92, "code": "SN7-7", "category": "PDF 7", "fp_tag": "FP", "question": "What type of learning problem does a decision tree primarily solve?", "options": ["Unsupervised clustering", "Reinforcement learning", "Supervised classification", "Sequence prediction"], "correct": 2}, {"id": 93, "code": "SN7-8", "category": "PDF 7", "fp_tag": "FP", "question": "Which criterion is commonly used to split nodes in decision tree learning?", "options": ["Euclidean distance", "Information gain", "Learning rate", "Margin size"], "correct": 1}, {"id": 94, "code": "SN7-9", "category": "PDF 7", "fp_tag": "FP", "question": "What is a major advantage of decision trees?", "options": ["They require large datasets", "They are easy to interpret", "They are always optimal", "They avoid overfitting automatically"], "correct": 1}, {"id": 95, "code": "SN7-10", "category": "PDF 7", "fp_tag": "FP", "question": "Which problem do decision trees commonly suffer from?", "options": ["Underfitting only", "Overfitting", "Lack of interpretability", "Requirement of kernels"], "correct": 1}, {"id": 96, "code": "SN7-11", "category": "PDF 7", "fp_tag": "", "question": "What technique is commonly used to reduce overfitting in decision trees?", "options": ["Increasing depth", "Pruning", "Increasing learning rate", "Removing labels"], "correct": 1}, {"id": 97, "code": "SN7-12", "category": "PDF 7", "fp_tag": "FP", "question": "What does correlation analysis help identify in datasets?", "options": ["Causal relationships only", "Feature relationships and dependencies", "Optimal classifiers", "Network architectures"], "correct": 1}, {"id": 98, "code": "SN7-13", "category": "PDF 7", "fp_tag": "FP", "question": "Why is feature selection important in machine learning?", "options": ["It increases dataset size", "It improves model accuracy and efficiency", "It removes the need for training", "It guarantees generalization"], "correct": 1}, {"id": 99, "code": "SN7-14", "category": "PDF 7", "fp_tag": "FP", "question": "Which method classifies a data point based on similarity to stored examples?", "options": ["Decision trees", "Naive Bayes", "Nearest Neighbor", "Perceptron"], "correct": 2}, {"id": 100, "code": "SN7-15", "category": "PDF 7", "fp_tag": "FP", "question": "What is a key drawback of the k-Nearest Neighbor method?", "options": ["It requires model training", "It has high computation cost at prediction time", "It assumes feature independence", "It cannot handle noise"], "correct": 1}, {"id": 101, "code": "SN7-16", "category": "PDF 7", "fp_tag": "FP", "question": "Which distance metric is commonly used in nearest neighbor methods?", "options": ["Manhattan distance", "Euclidean distance", "Hamming distance", "All of the above"], "correct": 3}, {"id": 102, "code": "SN7-17", "category": "PDF 7", "fp_tag": "", "question": "What happens when k is chosen too small in k-NN?", "options": ["Model underfits", "Model overfits", "Computation becomes impossible", "Distance metrics fail"], "correct": 1}, {"id": 103, "code": "SN7-18", "category": "PDF 7", "fp_tag": "", "question": "What happens when k is chosen too large in k-NN?", "options": ["Overfitting increases", "Decision boundaries become smoother", "Training fails", "Noise dominates"], "correct": 1}, {"id": 104, "code": "SN7-19", "category": "PDF 7", "fp_tag": "FP", "question": "Which learning paradigm does Naive Bayes belong to?", "options": ["Unsupervised learning", "Supervised learning", "Reinforcement learning", "Evolutionary learning"], "correct": 1}, {"id": 105, "code": "SN7-20", "category": "PDF 7", "fp_tag": "FP", "question": "Which statement about probabilistic classifiers is correct?", "options": ["They output only class labels", "They ignore uncertainty", "They model uncertainty explicitly", "They require linear separability"], "correct": 2}, {"id": 106, "code": "SN7-21", "category": "PDF 7", "fp_tag": "", "question": "Which factor most influences decision tree complexity?", "options": ["Learning rate", "Tree depth", "Distance metric", "Prior probabilities"], "correct": 1}, {"id": 107, "code": "SN7-22", "category": "PDF 7", "fp_tag": "FP", "question": "Why are ensemble methods like Random Forests effective?", "options": ["They use a single deep tree", "They combine multiple weak learners", "They eliminate randomness", "They avoid training"], "correct": 1}, {"id": 108, "code": "SN7-23", "category": "PDF 7", "fp_tag": "", "question": "Which concept helps evaluate relationships between numerical features?", "options": ["Entropy", "Correlation coefficient", "Kernel trick", "Margin"], "correct": 1}, {"id": 109, "code": "SN7-24", "category": "PDF 7", "fp_tag": "", "question": "Which classifier is most sensitive to irrelevant features?", "options": ["Naive Bayes", "k-Nearest Neighbor", "Decision Tree", "SVM"], "correct": 1}, {"id": 110, "code": "SN7-25", "category": "PDF 7", "fp_tag": "", "question": "Which statement best summarizes the goal of classification algorithms?", "options": ["Discover hidden clusters", "Predict continuous values", "Assign labels to unseen data", "Optimize memory usage"], "correct": 2}, {"id": 111, "code": "SN8-1", "category": "PDF 8", "fp_tag": "FP", "question": "How do modern data mining systems differ from early expert systems such as LEXMED?", "options": ["Modern systems rely only on symbolic rules", "Early expert systems used neural networks", "Modern systems adapt models automatically from data", "Early systems processed larger datasets"], "correct": 2}, {"id": 112, "code": "SN8-2", "category": "PDF 8", "fp_tag": "FP", "question": "What is a major advantage of adaptive learning models in data mining?", "options": ["Fixed decision rules", "Ability to improve with new data", "Elimination of preprocessing", "Reduced need for evaluation"], "correct": 1}, {"id": 113, "code": "SN8-3", "category": "PDF 8", "fp_tag": "FP", "question": "Why is visualization considered crucial in data mining practice?", "options": ["It replaces machine learning algorithms", "It reduces computational complexity", "It improves human interpretability of patterns", "It guarantees higher accuracy"], "correct": 2}, {"id": 114, "code": "SN8-4", "category": "PDF 8", "fp_tag": "FP", "question": "Which modern tools exemplify the importance of visualization in data mining?", "options": ["LISP and PROLOG", "Power BI and Tableau", "Assembly and C", "MySQL and MongoDB"], "correct": 1}, {"id": 115, "code": "SN8-5", "category": "PDF 8", "fp_tag": "FP", "question": "Why is human interpretability important in data mining results?", "options": ["Machines cannot process numbers", "Decisions often require human judgment", "Interpretability reduces data size", "It speeds up training"], "correct": 1}, {"id": 116, "code": "SN8-6", "category": "PDF 8", "fp_tag": "FP", "question": "What does the integration of statistics and AI in data mining reflect?", "options": ["The decline of symbolic AI", "The interdisciplinary nature of AI", "The elimination of learning algorithms", "The dominance of probability theory"], "correct": 1}, {"id": 117, "code": "SN8-7", "category": "PDF 8", "fp_tag": "FP", "question": "Which statistical concept is commonly integrated into data mining systems?", "options": ["Sorting algorithms", "Correlation analysis", "Stack operations", "Binary encoding"], "correct": 1}, {"id": 118, "code": "SN8-8", "category": "PDF 8", "fp_tag": "FP", "question": "What challenge arises from the explosion of big data in data mining?", "options": ["Lack of models", "Limited storage", "Scalability", "Low dimensionality"], "correct": 2}, {"id": 119, "code": "SN8-9", "category": "PDF 8", "fp_tag": "FP", "question": "How has cloud computing affected data mining practices?", "options": ["It reduced dataset sizes", "It limited access to tools", "It improved scalability and accessibility", "It eliminated preprocessing"], "correct": 2}, {"id": 120, "code": "SN8-10", "category": "PDF 8", "fp_tag": "FP", "question": "Which framework is commonly used for distributed data processing?", "options": ["OpenGL", "Hadoop", "MATLAB", "Unity"], "correct": 1}, {"id": 121, "code": "SN8-11", "category": "PDF 8", "fp_tag": "FP", "question": "What is a key ethical concern in real-world data mining applications?", "options": ["Algorithm speed", "Hardware cost", "Data privacy", "Model simplicity"], "correct": 2}, {"id": 122, "code": "SN8-12", "category": "PDF 8", "fp_tag": "FP", "question": "Which issue arises when biased data is used in data mining?", "options": ["Faster convergence", "Fairer models", "Discriminatory outcomes", "Improved generalization"], "correct": 2}, {"id": 123, "code": "SN8-13", "category": "PDF 8", "fp_tag": "FP", "question": "Why is explainability important in ethical AI and data mining?", "options": ["It reduces memory usage", "It increases model complexity", "It allows understanding and accountability", "It replaces validation"], "correct": 2}, {"id": 124, "code": "SN8-14", "category": "PDF 8", "fp_tag": "FP", "question": "What type of system is KNIME primarily designed to support?", "options": ["Game AI", "Workflow-based data analytics", "Operating systems", "Compiler optimization"], "correct": 1}, {"id": 125, "code": "SN8-15", "category": "PDF 8", "fp_tag": "FP", "question": "Where was KNIME originally developed?", "options": ["Stanford University", "MIT", "University of Konstanz", "Oxford University"], "correct": 2}, {"id": 126, "code": "SN8-16", "category": "PDF 8", "fp_tag": "FP", "question": "Who maintains and develops KNIME today?", "options": ["University of Konstanz", "IBM", "KNIME AG", "Google"], "correct": 2}, {"id": 127, "code": "SN8-17", "category": "PDF 8", "fp_tag": "FP", "question": "What is the main benefit of workflow-based analytics tools like KNIME?", "options": ["Manual coding only", "Visual programming and reproducibility", "Elimination of machine learning", "Fixed model structures"], "correct": 1}, {"id": 128, "code": "SN8-18", "category": "PDF 8", "fp_tag": "", "question": "Which phase of data mining benefits most from visualization?", "options": ["Data collection only", "Model deployment only", "Pattern discovery and evaluation", "Hardware selection"], "correct": 2}, {"id": 129, "code": "SN8-19", "category": "PDF 8", "fp_tag": "FP", "question": "Why is interdisciplinary knowledge important in modern data mining?", "options": ["Data mining is purely mathematical", "Real-world problems span multiple domains", "Algorithms work independently of context", "Models do not require interpretation"], "correct": 1}, {"id": 130, "code": "SN8-20", "category": "PDF 8", "fp_tag": "", "question": "Which application domain commonly raises ethical concerns in data mining?", "options": ["Sorting algorithms", "Healthcare", "Compiler design", "Graph theory"], "correct": 1}, {"id": 131, "code": "SN8-21", "category": "PDF 8", "fp_tag": "FP", "question": "What does scalability in data mining primarily refer to?", "options": ["Accuracy improvement", "Ability to handle increasing data volume", "Reduction of noise", "Feature selection"], "correct": 1}, {"id": 132, "code": "SN8-22", "category": "PDF 8", "fp_tag": "", "question": "Which factor most contributed to the rise of data mining?", "options": ["Small datasets", "Limited storage", "Availability of big data", "Decline of statistics"], "correct": 2}, {"id": 133, "code": "SN8-23", "category": "PDF 8", "fp_tag": "FP", "question": "Why are early expert systems less flexible than modern data mining systems?", "options": ["They lacked symbolic reasoning", "They relied on fixed rule bases", "They used neural networks", "They had too much data"], "correct": 1}, {"id": 134, "code": "SN8-24", "category": "PDF 8", "fp_tag": "", "question": "Which concept ensures responsible use of data mining technologies?", "options": ["Overfitting", "Automation", "Ethical governance", "Feature scaling"], "correct": 2}, {"id": 135, "code": "SN8-25", "category": "PDF 8", "fp_tag": "", "question": "Which statement best summarizes the role of data mining today?", "options": ["It replaces human decision-making", "It extracts actionable knowledge from large datasets", "It eliminates uncertainty", "It works only in academia"], "correct": 1}, {"id": 136, "code": "SN9-1", "category": "PDF 9", "fp_tag": "FP", "question": "Which biological component receives incoming signals in a neuron?", "options": ["Axon", "Synapse", "Dendrite", "Cell nucleus"], "correct": 2}, {"id": 137, "code": "SN9-2", "category": "PDF 9", "fp_tag": "FP", "question": "What causes a biological neuron to fire?", "options": ["Random activation", "External supervision", "Accumulated potential exceeding a threshold", "Maximum synaptic weight"], "correct": 2}, {"id": 138, "code": "SN9-3", "category": "PDF 9", "fp_tag": "FP", "question": "What is the primary function of synapses in biological neurons?", "options": ["Transmitting electrical impulses directly", "Storing long-term memory", "Acting as adjustable connection points", "Generating action potentials"], "correct": 2}, {"id": 139, "code": "SN9-4", "category": "PDF 9", "fp_tag": "FP", "question": "Which neurotransmitter type is mainly responsible for excitation or inhibition between neurons?", "options": ["DNA", "Hormones", "Neurotransmitters", "Enzymes"], "correct": 2}, {"id": 140, "code": "SN9-5", "category": "PDF 9", "fp_tag": "FP", "question": "What is meant by **biological neuroplasticity**?", "options": ["Fixed neuron connections", "Ability of neurons to change connections", "Random neuron firing", "Loss of synapses over time"], "correct": 1}, {"id": 141, "code": "SN9-6", "category": "PDF 9", "fp_tag": "FP", "question": "In artificial neural networks, what does a neuron compute?", "options": ["A probability distribution", "A symbolic rule", "A weighted sum followed by an activation function", "A random output"], "correct": 2}, {"id": 142, "code": "SN9-7", "category": "PDF 9", "fp_tag": "FP", "question": "Which model is considered one of the earliest formal neuron models?", "options": ["Backpropagation neuron", "McCulloch–Pitts neuron", "Hopfield neuron", "Boltzmann neuron"], "correct": 1}, {"id": 143, "code": "SN9-8", "category": "PDF 9", "fp_tag": "FP", "question": "What is the main purpose of modeling biological neurons in AI?", "options": ["Perfect biological simulation", "Hardware optimization", "Inspiration for computational learning systems", "Replacing symbolic AI"], "correct": 2}, {"id": 144, "code": "SN9-9", "category": "PDF 9", "fp_tag": "FP", "question": "Which learning principle is captured by the Hebb rule?", "options": ["Error minimization", "Reward maximization", "Correlation-based weight strengthening", "Gradient descent"], "correct": 2}, {"id": 145, "code": "SN9-10", "category": "PDF 9", "fp_tag": "FP", "question": "The phrase *“cells that fire together wire together”* refers to:", "options": ["Backpropagation", "Hebbian learning", "Reinforcement learning", "Supervised learning"], "correct": 1}, {"id": 146, "code": "SN9-11", "category": "PDF 9", "fp_tag": "FP", "question": "What is the main function of a Hopfield network?", "options": ["Regression", "Classification", "Associative memory", "Feature extraction"], "correct": 2}, {"id": 147, "code": "SN9-12", "category": "PDF 9", "fp_tag": "FP", "question": "How is information stored in a Hopfield network?", "options": ["In explicit rules", "In neuron biases", "In synaptic weights", "In activation functions"], "correct": 2}, {"id": 148, "code": "SN9-13", "category": "PDF 9", "fp_tag": "FP", "question": "What does a stable state in a Hopfield network correspond to?", "options": ["Maximum entropy", "Random firing", "Local minimum of the energy function", "Maximum learning rate"], "correct": 2}, {"id": 149, "code": "SN9-14", "category": "PDF 9", "fp_tag": "FP", "question": "Why is energy minimization important in Hopfield networks?", "options": ["It speeds up training", "It ensures convergence to stored patterns", "It increases storage capacity infinitely", "It eliminates noise completely"], "correct": 1}, {"id": 150, "code": "SN9-15", "category": "PDF 9", "fp_tag": "FP", "question": "What happens if too many patterns are stored in a Hopfield network?", "options": ["Accuracy improves", "Memory capacity increases linearly", "Network becomes unstable", "Training becomes supervised"], "correct": 2}, {"id": 151, "code": "SN9-16", "category": "PDF 9", "fp_tag": "", "question": "Which factor mainly limits the storage capacity of Hopfield networks?", "options": ["Number of input samples", "Number of neurons", "Learning rate", "Activation function type"], "correct": 1}, {"id": 152, "code": "SN9-17", "category": "PDF 9", "fp_tag": "FP", "question": "What type of connections exist in a standard Hopfield network?", "options": ["Directed and asymmetric", "Random and dynamic", "Symmetric and fully connected", "Sparse and hierarchical"], "correct": 2}, {"id": 153, "code": "SN9-18", "category": "PDF 9", "fp_tag": "FP", "question": "Which concept links Hopfield networks to physical systems?", "options": ["Bayesian inference", "Energy landscapes", "Decision boundaries", "Kernel functions"], "correct": 1}, {"id": 154, "code": "SN9-19", "category": "PDF 9", "fp_tag": "FP", "question": "What is associative memory?", "options": ["Memory indexed by time", "Memory retrieved by exact address", "Memory retrieved from partial or noisy input", "Memory stored externally"], "correct": 2}, {"id": 155, "code": "SN9-20", "category": "PDF 9", "fp_tag": "FP", "question": "Which learning rule is typically used to store patterns in Hopfield networks?", "options": ["Gradient descent", "Binary Hebb rule", "Backpropagation", "Reinforcement learning"], "correct": 1}, {"id": 156, "code": "SN9-21", "category": "PDF 9", "fp_tag": "FP", "question": "Why are Hopfield networks not suitable for deep learning tasks?", "options": ["They require labeled data", "They lack differentiability for backpropagation", "They overfit easily", "They need large datasets"], "correct": 1}, {"id": 157, "code": "SN9-22", "category": "PDF 9", "fp_tag": "", "question": "Which modern models are conceptually related to Hopfield networks?", "options": ["Decision trees", "Support Vector Machines", "Energy-based models", "Naive Bayes classifiers"], "correct": 2}, {"id": 158, "code": "SN9-23", "category": "PDF 9", "fp_tag": "FP", "question": "What role did Hopfield networks play in AI history?", "options": ["They replaced symbolic reasoning", "They inspired modern neural architectures", "They solved general intelligence", "They eliminated supervised learning"], "correct": 1}, {"id": 159, "code": "SN9-24", "category": "PDF 9", "fp_tag": "", "question": "Which property ensures convergence in Hopfield networks?", "options": ["Random initialization", "Asymmetric weights", "Energy function minimization", "High learning rate"], "correct": 2}, {"id": 160, "code": "SN9-25", "category": "PDF 9", "fp_tag": "FP", "question": "What distinguishes biological neurons from artificial neurons most clearly?", "options": ["Use of logic", "Exact mathematical modeling", "Massive parallelism and adaptability", "Digital computation"], "correct": 2}, {"id": 161, "code": "SN9-26", "category": "PDF 9", "fp_tag": "", "question": "Which component is abstracted away in artificial neuron models?", "options": ["Input signals", "Synaptic weights", "Detailed biochemical processes", "Activation functions"], "correct": 2}, {"id": 162, "code": "SN9-27", "category": "PDF 9", "fp_tag": "FP", "question": "Why are artificial neurons considered simplified models?", "options": ["They lack inputs", "They ignore most biological complexity", "They do not learn", "They are symbolic"], "correct": 1}, {"id": 163, "code": "SN9-28", "category": "PDF 9", "fp_tag": "", "question": "Which statement about Hebbian learning is correct?", "options": ["It minimizes global error", "It is supervised", "It strengthens correlated activations", "It requires labeled outputs"], "correct": 2}, {"id": 164, "code": "SN9-29", "category": "PDF 9", "fp_tag": "", "question": "Which learning paradigm best describes Hopfield networks?", "options": ["Supervised learning", "Unsupervised learning", "Reinforcement learning", "Evolutionary learning"], "correct": 1}, {"id": 165, "code": "SN9-30", "category": "PDF 9", "fp_tag": "", "question": "Which limitation most strongly restricts Hopfield networks in practice?", "options": ["High training cost", "Limited storage capacity", "Requirement of labels", "Kernel selection"], "correct": 1}, {"id": 166, "code": "SN10-1", "category": "PDF 10", "fp_tag": "FP", "question": "What is the main objective of the backpropagation algorithm?", "options": ["To randomly initialize network weights", "To propagate inputs forward through the network", "To minimize the error function by adjusting weights", "To eliminate hidden layers"], "correct": 2}, {"id": 167, "code": "SN10-2", "category": "PDF 10", "fp_tag": "FP", "question": "Why must activation functions be differentiable in backpropagation?", "options": ["To speed up computation", "To apply the chain rule of calculus", "To reduce overfitting", "To simplify network architecture"], "correct": 1}, {"id": 168, "code": "SN10-3", "category": "PDF 10", "fp_tag": "FP", "question": "Which limitation of the perceptron model led to the development of multi-layer neural networks?", "options": ["Inability to process large datasets", "Inability to learn non-linearly separable functions", "High computational cost", "Sensitivity to noise"], "correct": 1}, {"id": 169, "code": "SN10-4", "category": "PDF 10", "fp_tag": "FP", "question": "Which problem is classically used to demonstrate the failure of single-layer perceptrons?", "options": ["AND", "OR", "XOR", "NAND"], "correct": 2}, {"id": 170, "code": "SN10-5", "category": "PDF 10", "fp_tag": "FP", "question": "Backpropagation is primarily applied to which type of neural network?", "options": ["Recurrent neural networks", "Feedforward neural networks", "Bayesian networks", "Hopfield networks"], "correct": 1}, {"id": 171, "code": "SN10-6", "category": "PDF 10", "fp_tag": "FP", "question": "What role does the error (loss) function play in backpropagation?", "options": ["It defines network topology", "It measures the difference between predicted and target outputs", "It initializes weights", "It selects input features"], "correct": 1}, {"id": 172, "code": "SN10-7", "category": "PDF 10", "fp_tag": "FP", "question": "Which loss function is commonly used in classical backpropagation examples in the slides?", "options": ["Cross-entropy loss", "Hinge loss", "Sum of squared errors", "KL-divergence"], "correct": 2}, {"id": 173, "code": "SN10-8", "category": "PDF 10", "fp_tag": "FP", "question": "What does gradient descent attempt to optimize during training?", "options": ["Number of neurons", "Network depth", "Error function", "Input dimensionality"], "correct": 2}, {"id": 174, "code": "SN10-9", "category": "PDF 10", "fp_tag": "", "question": "What is the most likely consequence of choosing a very large learning rate?", "options": ["Very slow convergence", "No weight updates", "Oscillation or divergence during training", "Guaranteed global minimum"], "correct": 2}, {"id": 175, "code": "SN10-10", "category": "PDF 10", "fp_tag": "FP", "question": "What happens if the learning rate is chosen too small?", "options": ["Training becomes unstable", "Training converges very slowly", "The model overfits immediately", "Gradients explode"], "correct": 1}, {"id": 176, "code": "SN10-11", "category": "PDF 10", "fp_tag": "FP", "question": "Which mathematical principle enables error propagation from output to hidden layers?", "options": ["Linear algebra", "Probability theory", "Chain rule", "Bayesian inference"], "correct": 2}, {"id": 177, "code": "SN10-12", "category": "PDF 10", "fp_tag": "", "question": "Which layer directly computes the output error in backpropagation?", "options": ["Input layer", "First hidden layer", "Output layer", "All layers simultaneously"], "correct": 2}, {"id": 178, "code": "SN10-13", "category": "PDF 10", "fp_tag": "", "question": "In backpropagation, how are hidden layer errors computed?", "options": ["Randomly", "From the output layer errors", "From the input data", "From the bias values"], "correct": 1}, {"id": 179, "code": "SN10-14", "category": "PDF 10", "fp_tag": "FP", "question": "Why are non-differentiable activation functions problematic for backpropagation?", "options": ["They increase memory usage", "Gradients cannot be computed", "They slow down inference", "They require more data"], "correct": 1}, {"id": 180, "code": "SN10-15", "category": "PDF 10", "fp_tag": "", "question": "Which activation function was historically popular but can cause vanishing gradients?", "options": ["ReLU", "Linear", "Sigmoid", "Softmax"], "correct": 2}, {"id": 181, "code": "SN10-16", "category": "PDF 10", "fp_tag": "", "question": "What does the vanishing gradient problem mainly affect?", "options": ["Input normalization", "Deep neural networks", "Linear classifiers", "Output layer only"], "correct": 1}, {"id": 182, "code": "SN10-17", "category": "PDF 10", "fp_tag": "FP", "question": "Why is differentiability essential for gradient-based learning?", "options": ["It reduces noise", "It allows analytical gradient computation", "It simplifies datasets", "It guarantees optimality"], "correct": 1}, {"id": 183, "code": "SN10-18", "category": "PDF 10", "fp_tag": "", "question": "Which component controls the step size of weight updates?", "options": ["Bias", "Momentum", "Learning rate", "Activation function"], "correct": 2}, {"id": 184, "code": "SN10-19", "category": "PDF 10", "fp_tag": "FP", "question": "What is the main advantage of multi-layer neural networks over perceptrons?", "options": ["Faster training", "Lower memory usage", "Ability to model nonlinear decision boundaries", "Simpler mathematical formulation"], "correct": 2}, {"id": 185, "code": "SN10-20", "category": "PDF 10", "fp_tag": "", "question": "Which optimization problem does neural network training correspond to?", "options": ["Sorting", "Search", "Function minimization", "Clustering"], "correct": 2}, {"id": 186, "code": "SN10-21", "category": "PDF 10", "fp_tag": "FP", "question": "Which classifier aims to maximize the margin between classes?", "options": ["Perceptron", "Naive Bayes", "Support Vector Machine", "k-NN"], "correct": 2}, {"id": 187, "code": "SN10-22", "category": "PDF 10", "fp_tag": "FP", "question": "What is the core idea behind the kernel trick in SVMs?", "options": ["Reducing dimensionality", "Mapping data to higher-dimensional space", "Eliminating support vectors", "Avoiding optimization"], "correct": 1}, {"id": 188, "code": "SN10-23", "category": "PDF 10", "fp_tag": "FP", "question": "Why does maximizing the margin improve generalization in SVMs?", "options": ["It reduces training time", "It increases model complexity", "It reduces sensitivity to noise", "It eliminates outliers"], "correct": 2}, {"id": 189, "code": "SN10-24", "category": "PDF 10", "fp_tag": "", "question": "Which kernel is commonly used for non-linear classification?", "options": ["Linear", "Polynomial", "Radial Basis Function (RBF)", "Identity"], "correct": 2}, {"id": 190, "code": "SN10-25", "category": "PDF 10", "fp_tag": "", "question": "What do support vectors represent?", "options": ["All training samples", "Misclassified samples", "Boundary-defining samples", "Random points"], "correct": 2}, {"id": 191, "code": "SN10-26", "category": "PDF 10", "fp_tag": "", "question": "Which statement best describes backpropagation?", "options": ["A rule-based inference method", "A supervised learning algorithm", "An unsupervised clustering method", "A symbolic reasoning system"], "correct": 1}, {"id": 192, "code": "SN10-27", "category": "PDF 10", "fp_tag": "FP", "question": "Why is backpropagation considered a breakthrough in neural network history?", "options": ["It eliminated the need for data", "It enabled training of multi-layer networks", "It replaced symbolic AI", "It guarantees global optimality"], "correct": 1}, {"id": 193, "code": "SN10-28", "category": "PDF 10", "fp_tag": "", "question": "Which factor most strongly affects convergence speed?", "options": ["Number of classes", "Learning rate", "Dataset size", "Output labels"], "correct": 1}, {"id": 194, "code": "SN10-29", "category": "PDF 10", "fp_tag": "", "question": "What does a local minimum represent in training?", "options": ["Best possible solution", "A point where gradients are zero but not global optimum", "Model failure", "Overfitting state"], "correct": 1}, {"id": 195, "code": "SN10-30", "category": "PDF 10", "fp_tag": "", "question": "Why can training get stuck in local minima?", "options": ["Discrete weights", "Non-convex error surfaces", "Linear activation functions", "Small datasets"], "correct": 1}, {"id": 196, "code": "SN10-31", "category": "PDF 10", "fp_tag": "", "question": "Which method helps reduce oscillations during gradient descent?", "options": ["Feature scaling", "Momentum", "Dropout", "Regularization"], "correct": 1}, {"id": 197, "code": "SN10-32", "category": "PDF 10", "fp_tag": "", "question": "What is the role of bias terms in neural networks?", "options": ["Increase input size", "Shift activation thresholds", "Normalize gradients", "Reduce overfitting"], "correct": 1}, {"id": 198, "code": "SN10-33", "category": "PDF 10", "fp_tag": "", "question": "Which statement about SVMs is correct?", "options": ["They minimize squared error", "They maximize classification margin", "They require differentiable activation functions", "They are unsupervised"], "correct": 1}, {"id": 199, "code": "SN10-34", "category": "PDF 10", "fp_tag": "", "question": "Compared to perceptrons, SVMs primarily differ in:", "options": ["Use of kernels and margins", "Requirement of labeled data", "Binary output", "Linear decision boundaries only"], "correct": 0}, {"id": 200, "code": "SN10-35", "category": "PDF 10", "fp_tag": "", "question": "Which learning paradigm do both backpropagation and SVMs belong to?", "options": ["Unsupervised learning", "Reinforcement learning", "Supervised learning", "Evolutionary learning"], "correct": 2}]